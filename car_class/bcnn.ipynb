{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import sys\n",
    "import PIL.Image as pil_image\n",
    "import glob\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from myutil import *\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model,Model\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Flatten\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def original(img):\n",
    "    \"\"\"\n",
    "    return the original pic\n",
    "    \"\"\"\n",
    "    tmp = np.zeros_like(img)\n",
    "    for i in range(3):\n",
    "        tmp[:,:,i] = img[:,:,i] - img[:,:,i].min()\n",
    "    return tmp.astype(np.uint8)\n",
    "\n",
    "def lookup(d, key, i):\n",
    "    \"\"\"\n",
    "    looking up key value i in dictionary d \n",
    "    \"\"\"\n",
    "    if key == 'make+model':\n",
    "        for item in d:\n",
    "            if item['pp_brand_id']+' '+item['pp_genre_id'] == i:\n",
    "                return item['chinese']\n",
    "    else:\n",
    "        for item in d:\n",
    "            if item[key] == i:\n",
    "                return item['chinese']\n",
    "            \n",
    "def crop_img(img, box):\n",
    "    \"\"\"\n",
    "    box: left, top, right, bottom\n",
    "    \"\"\"\n",
    "    w, h = img.size\n",
    "    box = [box[0]*w, box[1]*h,box[2]*w,box[3]*h]\n",
    "    return img.crop(box)\n",
    "            \n",
    "def load_img(path, grayscale=False, target_size=None, box=None):\n",
    "    \"\"\"Loads an image into PIL format.\n",
    "    # Arguments\n",
    "        path: Path to image file\n",
    "        grayscale: Boolean, whether to load the image as grayscale.\n",
    "        target_size: Either `None` (default to original size)\n",
    "            or tuple of ints `(img_height, img_width)`.\n",
    "        box: The crop rectangle, as a (left, upper, right, lower)-tuple.\n",
    "    # Returns\n",
    "        A PIL Image instance.\n",
    "    # Raises\n",
    "        ImportError: if PIL is not available.\n",
    "    \"\"\"\n",
    "    if pil_image is None:\n",
    "        raise ImportError('Could not import PIL.Image. '\n",
    "                          'The use of `array_to_img` requires PIL.')\n",
    "    img = pil_image.open(path)\n",
    "    if grayscale:\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "    else:\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "    if box:\n",
    "        img = crop_img(img, box)\n",
    "        \n",
    "    if target_size:\n",
    "        hw_tuple = (target_size[1], target_size[0])\n",
    "        #resize(w, h)\n",
    "        if img.size != hw_tuple:\n",
    "            img = img.resize(hw_tuple)\n",
    "    return img\n",
    "            \n",
    "def load_data(image_paths, labels, num_of_class=10, target_size=(227, 227), box=None):\n",
    "    \"\"\"\n",
    "    Given list of paths, resize and bounding box load images as one numpy array of shape\n",
    "        (num_images, crop_size, crop_size, channel)\n",
    "        box:[top, left, bottom, right]\n",
    "    :return X: image array\n",
    "     return y: one hot encoded labels\n",
    "    \"\"\"\n",
    "    if box:\n",
    "        X = np.zeros((len(image_paths), crop_size[0],crop_size[1], 3))\n",
    "        ## google output box :## 0: top 1: left 2 lower 3 right\n",
    "        for i,path in enumerate(image_paths):\n",
    "            new_box = (box[i][1],box[i][0],box[i][3], box[i][2])\n",
    "            X[i, :] = img_to_array(load_img(path, target_size=target_size, box=new_box))\n",
    "        y = np_utils.to_categorical(labels, num_of_class)\n",
    "        return X, y\n",
    "    else:\n",
    "        X = np.zeros((len(image_paths), crop_size[0],crop_size[1], 3))\n",
    "        for i,path in enumerate(image_paths):\n",
    "            X[i, :] = img_to_array(load_img(path, target_size=target_size))\n",
    "        y = np_utils.to_categorical(labels, num_of_class)\n",
    "        return X, y\n",
    "    \n",
    "def load_data_flip(image_paths, labels, num_of_class=10, target_size=(227, 227), box=None):\n",
    "    \"\"\"\n",
    "    Given list of paths, resize and bounding box load images as one numpy array of shape\n",
    "        (num_images, crop_size, crop_size, channel)\n",
    "        box:[top, left, bottom, right]\n",
    "    :return X: image array\n",
    "     return y: one hot encoded labels\n",
    "    \"\"\"\n",
    "    if box.any():\n",
    "        X = np.zeros((len(image_paths), crop_size[0],crop_size[1], 3))\n",
    "        ## google output box :## 0: top 1: left 2 lower 3 right\n",
    "        for i,path in enumerate(image_paths):\n",
    "            new_box = (box[i][1],box[i][0],box[i][3], box[i][2])\n",
    "            if bool(random.getrandbits(1)):\n",
    "                X[i, :] = img_to_array(load_img(path, target_size=target_size, box=new_box))\n",
    "            else: \n",
    "                X[i, :] = img_to_array(load_img(path, target_size=target_size, box=new_box))[:,::-1,:]\n",
    "        y = np_utils.to_categorical(labels, num_of_class)\n",
    "        return X, y\n",
    "    else:\n",
    "        X = np.zeros((len(image_paths), crop_size[0],crop_size[1], 3))\n",
    "        for i,path in enumerate(image_paths):\n",
    "            if bool(random.getrandbits(1)):\n",
    "                X[i, :] = img_to_array(load_img(path, target_size=target_size))\n",
    "            else: \n",
    "                X[i, :] = img_to_array(load_img(path, target_size=target_size))[:,::-1,:]\n",
    "        y = np_utils.to_categorical(labels, num_of_class)\n",
    "        return X, y\n",
    "    \n",
    "def judge_box(left, right, left_t, right_t):\n",
    "    if left < left_t and right > right_t:\n",
    "        return True\n",
    "\n",
    "def load_box(path,x_threshold=0.51,x_threshold2=0.51):\n",
    "    if x_threshold > x_threshold2:\n",
    "        print 'threshold error'\n",
    "    with open(path) as f:\n",
    "        bb_list = np.load(f).item()\n",
    "    result = defaultdict(list)\n",
    "    ## delete left > 0.5 right border < 0.5\n",
    "    ## 0: top 1: left 2 lower 3 right\n",
    "    for k in bb_list.keys():\n",
    "        if len(bb_list[k]) == 1:\n",
    "            result[k] = bb_list[k]\n",
    "            continue\n",
    "        for bb_box in bb_list[k]:\n",
    "            if judge_box(left=bb_box[1], right=bb_box[3], left_t=x_threshold, right_t=x_threshold2):\n",
    "                result[k].append(bb_box)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_arrays(batch_size, target_size = (448,448)):\n",
    "    sample_number = len(train_paths)\n",
    "    box = np.array([box_list['/'.join(item.split('/')[-3:])][0] for item in train_paths])\n",
    "    while True:\n",
    "        if shuffle == True :\n",
    "            idx1 = list(range(len(train_labels[0])))\n",
    "            random.shuffle(idx1)\n",
    "            \n",
    "        for i in range(0,sample_number,batch_size):\n",
    "            if i + batch_size > sample_number:\n",
    "                idx = idx1[i:]\n",
    "            else:\n",
    "                idx = idx1[i:i+batch_size]\n",
    "            \n",
    "            X_train, y_train = load_data_flip(train_paths[idx], train_labels[0][idx], num_of_makes, target_size, box[idx])\n",
    "            y_train2 = np_utils.to_categorical(train_labels[1][idx], num_of_models)\n",
    "            #y_train3 = np_utils.to_categorical(train_labels[2][idx], num_of_types)\n",
    "            X_train = preprocess_input(X_train)\n",
    "            ## no car pic\n",
    "            i_tmp = i % 30489\n",
    "            X_negative, y_negative = load_data(train_negative[i_tmp:i_tmp+2], negative_label[0][i_tmp:i_tmp+2], num_of_makes, target_size)\n",
    "            y_negative2 = np_utils.to_categorical(negative_label[0][i_tmp:i_tmp+2], num_of_models)\n",
    "            #y_negative3 = np_utils.to_categorical(negative_label[0][i_tmp:i_tmp+2], num_of_types)\n",
    "            #yield (X_train, {'make':y_train, 'model':y_train2})\n",
    "            if len(X_train) == 0:\n",
    "                print i, X_train\n",
    "            yield (np.concatenate((X_train, X_negative), axis=0),\n",
    "                   {'make':np.concatenate((y_train, y_negative), axis=0), \n",
    "                    'model':np.concatenate((y_train2, y_negative2), axis=0)\n",
    "                    }\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train brand num: 230 genre num: 1581\n",
      "img num: 41865 validaiont img num: 11508\n"
     ]
    }
   ],
   "source": [
    "# setting\n",
    "#(img_height, img_width)\n",
    "crop_size = (448, 448)\n",
    "data_dir = '/root/playground/START/car_class/yiche_image/'\n",
    "shuffle = True\n",
    "alpha = 0.5\n",
    "model_name = ''\n",
    "\n",
    "\n",
    "\n",
    "# key:genre(int) value:1~10 find in type list\n",
    "genre_type_map = np.load(os.path.join(data_dir,'map/yiche_car_type.npy')).item()\n",
    "\n",
    "\n",
    "## key: box_list('20169/3223/bl110088.jpg', value:box\n",
    "box_list =load_box(os.path.join(data_dir,'map/yiche_box.npy'))\n",
    "\n",
    "## car_info\n",
    "car_info = np.load(os.path.join(data_dir,'map/yiche_car_info_npy.npy'))\n",
    "\n",
    "train_paths = []\n",
    "train_labels = defaultdict(list)\n",
    "train_makes = []\n",
    "train_models = []\n",
    "train_types = []\n",
    "\n",
    "val_paths = []\n",
    "val_labels = defaultdict(list)\n",
    "val_makes = []\n",
    "val_models = []\n",
    "val_types = []\n",
    "\n",
    "pos = car_info[0]['imgs'].keys()\n",
    "\n",
    "# indentify make/model/car_id.jpg\n",
    "brands = os.listdir(data_dir+'yiche_processed')\n",
    "for brand in brands:\n",
    "    genres = os.listdir(os.path.join(data_dir,'yiche_processed', brand))\n",
    "    for genre in genres:\n",
    "        for po in pos:\n",
    "            pics = glob.glob(os.path.join(data_dir,'yiche_processed', brand, genre,po+'*.jpg'))\n",
    "            if len(pics)<3:\n",
    "                split = len(pics)\n",
    "            else:\n",
    "                split = len(pics)*4/5\n",
    "            # train data\n",
    "            for pic in pics[:split]:\n",
    "                # two pic in a row\n",
    "                train_paths += [pic]\n",
    "                # label|\n",
    "                train_models += [brand + ' ' +genre]\n",
    "                train_makes += [brand]\n",
    "                train_types += [genre_type_map[int(genre)]]\n",
    "            \n",
    "            #validation data\n",
    "            for pic in pics[split:]:\n",
    "                # two pic in a row\n",
    "                val_paths += [pic]\n",
    "                # label|\n",
    "                val_models += [brand + ' ' +genre]\n",
    "                val_makes += [brand]\n",
    "                val_types += [genre_type_map[int(genre)]]\n",
    "\n",
    "assert(len(train_makes) == len(train_paths))\n",
    "\n",
    "#indexing building\n",
    "l2i_makes = sorted(list(set(train_makes + ['-1'])))\n",
    "l2i_models = sorted(list(set(train_models + ['-1'])))\n",
    "\n",
    "# for multiple label\n",
    "train_labels[0] = np.array([l2i_makes.index(item) for item in train_makes])\n",
    "train_labels[1] = np.array([l2i_models.index(item) for item in train_models])\n",
    "train_labels[2] = np.array(train_types)\n",
    "\n",
    "val_labels[0] = np.array([l2i_makes.index(item) for item in val_makes])\n",
    "val_labels[1] = np.array([l2i_models.index(item) for item in val_models])\n",
    "val_labels[2] = np.array(val_types)\n",
    "train_paths = np.array(train_paths)\n",
    "\n",
    "# data info\n",
    "num_of_models = len(l2i_models)\n",
    "num_of_makes = len(l2i_makes)\n",
    "\n",
    "#saving mapping info\n",
    "#np.save(os.path.join(data_dir,'map/l2i_make'),l2i_makes)\n",
    "#np.save(os.path.join(data_dir,'map/l2i_models'),l2i_models)\n",
    "\n",
    "\n",
    "print 'train brand num:',len(l2i_makes),'genre num:', len(l2i_models)\n",
    "print  'img num:',len(train_makes), 'validaiont img num:', len(val_makes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41865 30491\n"
     ]
    }
   ],
   "source": [
    "## Caltech 256 except 252 car side\n",
    "train_negative = []\n",
    "cal_path = glob.glob('/root/playground/START/car_class/256_ObjectCategories/*')\n",
    "for item in cal_path:\n",
    "    train_negative += glob.glob(item + '/*.jpg')\n",
    "    \n",
    "random.shuffle(train_negative)\n",
    "train_negative = train_negative\n",
    "negative_label = [[0]*len(train_negative), [0]*len(train_negative)]\n",
    "print len(train_labels[0]), len(train_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model complete\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "config = tf.ConfigProto(device_count={'CPU' : 1, 'GPU' : 0})\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "output_dim = [230, 1581]\n",
    "img = tf.placeholder(tf.float32, shape=(None, 448, 448, 3))\n",
    "label_make = tf.placeholder(tf.float32, shape=(None, output_dim[0]))\n",
    "label_model = tf.placeholder(tf.float32, shape=(None, output_dim[1]))\n",
    "\n",
    "base_model = VGG16(input_tensor=img, include_top=False)\n",
    "\n",
    "# last conv layer of vgg\n",
    "conv5_3 = base_model.layers[-2].output\n",
    "\n",
    "# bilinear pool\n",
    "phi_I = tf.reshape(tf.einsum('ijkm,ijkn->imn', conv5_3, conv5_3), [-1, 512*512])\n",
    "phi_I = tf.divide(phi_I,784.0)\n",
    "y_ssqrt = tf.multiply(tf.sign(phi_I),tf.sqrt(tf.abs(phi_I)+1e-12))\n",
    "z_l2 = tf.nn.l2_normalize(y_ssqrt, dim=1)\n",
    "\n",
    "# softmax\n",
    "fc1 = Dense(output_dim[0], activation='softmax', name='make')\n",
    "fc2 = Dense(output_dim[1], activation='softmax', name='model')\n",
    "pred_make = fc1(z_l2)\n",
    "pred_model = fc2(z_l2)\n",
    "\n",
    "# create multitask softmax layer\n",
    "loss_make = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label_make, logits=pred_make))\n",
    "loss_model = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label_model, logits=pred_model))\n",
    "loss_joint = 0.5*loss_make + 0.5*loss_model\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=0.9, momentum=0.9).minimize(loss_joint)\n",
    "\n",
    "# evaluation metric\n",
    "correct_prediction_make = tf.equal(tf.argmax(pred_make, 1), tf.argmax(label_make, 1))\n",
    "accuracy_make = tf.reduce_mean(tf.cast(correct_prediction_make, tf.float32))\n",
    "\n",
    "correct_prediction_model = tf.equal(tf.argmax(pred_model, 1), tf.argmax(label_model, 1))\n",
    "accuracy_model = tf.reduce_mean(tf.cast(correct_prediction_model, tf.float32))\n",
    "\n",
    "# initialization\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# laod vgg weight\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "base_model.load_weights(weights_path)\n",
    "print 'load model complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "3/8373\t loss_make:5.438079 loss_model:7.365817 loss_joint:6.401948 0.2857\t0.0000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-381b44791c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch_y2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         res = sess.run([loss_make, loss_model,loss_joint, accuracy_make, accuracy_model,optimizer], \n\u001b[0;32m---> 15\u001b[0;31m                        feed_dict={img: batch_xs, label_make: batch_y1,label_model:batch_y2 })\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0msout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d/%d\\t loss_make:%5f loss_model:%5f loss_joint:%5f %.4f\\t%.4f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "sout = sys.stdout\n",
    "print('Starting training')\n",
    "lr = 1.0\n",
    "break_training_epoch = 1\n",
    "generator = generate_arrays(batch_size, crop_size)\n",
    "for epoch in range(break_training_epoch):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(len(train_paths)/batch_size)\n",
    "    for b in range(total_batch):\n",
    "        batch_xs, batch_ys = generator.next()\n",
    "        batch_y1 = batch_ys['make']\n",
    "        batch_y2 = batch_ys['model']\n",
    "        res = sess.run([loss_make, loss_model,loss_joint, accuracy_make, accuracy_model,optimizer], \n",
    "                       feed_dict={img: batch_xs, label_make: batch_y1,label_model:batch_y2 })\n",
    "        sout.write(\"%d/%d\\t loss_make:%5f loss_model:%5f loss_joint:%5f %.4f\\t%.4f\"%(b,total_batch,res[0],res[1],res[2], res[3],res[4])) \n",
    "        sout.flush()\n",
    "        sout.write('\\r')\n",
    "    sout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[  1.66219279e-01,   1.42701820e-01,  -4.02113283e-03, ...,\n",
       "             6.18828237e-02,  -1.74057148e-02,  -3.00644431e-02],\n",
       "          [  9.46945231e-03,   3.87477316e-03,   5.08365929e-02, ...,\n",
       "            -2.77981739e-02,   1.71373668e-03,   6.82722731e-03],\n",
       "          [  6.32681847e-02,   2.12877709e-02,  -1.63465310e-02, ...,\n",
       "             8.80054955e-04,   6.68104272e-03,  -1.41139806e-03],\n",
       "          ..., \n",
       "          [  3.47490981e-03,   8.47019628e-02,  -4.07223180e-02, ...,\n",
       "            -1.13523193e-02,  -7.48998486e-03,   3.19077494e-03],\n",
       "          [  5.97234145e-02,   4.97663505e-02,  -3.23118735e-03, ...,\n",
       "             1.43114366e-02,   3.03175431e-02,  -4.23925705e-02],\n",
       "          [  1.33459672e-01,   4.95484173e-02,  -1.78808011e-02, ...,\n",
       "             2.25385167e-02,   3.02020740e-02,  -2.17075031e-02]],\n",
       " \n",
       "         [[  2.12007999e-01,   2.10127644e-02,  -1.47626130e-02, ...,\n",
       "             2.29580477e-02,   1.23102348e-02,  -3.08422819e-02],\n",
       "          [ -2.62175221e-03,   7.42094172e-03,   6.74030930e-02, ...,\n",
       "            -3.06594316e-02,   1.80578313e-03,   4.27369215e-03],\n",
       "          [  2.27197763e-02,  -1.07841045e-02,  -1.31095545e-02, ...,\n",
       "            -1.15751950e-02,   4.18359675e-02,  -1.92268589e-03],\n",
       "          ..., \n",
       "          [ -2.70304317e-03,   7.41161704e-02,  -3.32262330e-02, ...,\n",
       "            -1.10277236e-02,   1.39831286e-02,   5.34419343e-03],\n",
       "          [ -3.20506282e-02,  -2.40584910e-02,  -4.52397857e-03, ...,\n",
       "            -6.04042644e-03,   2.01962605e-01,  -5.04491515e-02],\n",
       "          [  1.68114193e-02,  -2.33167298e-02,  -1.40886130e-02, ...,\n",
       "            -7.79278344e-03,   1.28428593e-01,  -2.58184522e-02]],\n",
       " \n",
       "         [[ -5.91698708e-03,  -2.26223674e-02,   4.88128467e-03, ...,\n",
       "             4.13784146e-04,  -4.84175496e-02,   1.63675251e-03],\n",
       "          [ -3.93767562e-03,   9.07397643e-03,   5.36517277e-02, ...,\n",
       "            -2.56106984e-02,  -4.17886395e-03,   2.47476017e-03],\n",
       "          [ -3.07008922e-02,  -1.09781921e-02,  -3.69096454e-03, ...,\n",
       "            -1.19221993e-02,  -1.39777903e-02,   8.52933805e-03],\n",
       "          ..., \n",
       "          [  5.83332591e-03,   2.96198055e-02,  -3.56571227e-02, ...,\n",
       "            -1.01153394e-02,   5.06090466e-03,  -2.86859111e-03],\n",
       "          [ -7.80934095e-02,  -1.95693132e-02,   2.14814320e-02, ...,\n",
       "             7.42452731e-03,   5.41617945e-02,  -2.35790759e-02],\n",
       "          [ -7.82641992e-02,  -2.47034207e-02,   1.36250593e-02, ...,\n",
       "            -7.53259566e-03,  -2.59861015e-02,   4.52143652e-03]]],\n",
       " \n",
       " \n",
       "        [[[  1.99202523e-01,   5.03257252e-02,  -1.93236247e-02, ...,\n",
       "             1.62308700e-02,  -1.15369558e-02,   1.55777042e-03],\n",
       "          [ -1.38656620e-03,   4.52297740e-03,   6.65066689e-02, ...,\n",
       "            -3.00004911e-02,   1.71904117e-04,  -1.11898372e-03],\n",
       "          [  2.14257818e-02,   1.79782789e-03,  -1.76792312e-02, ...,\n",
       "            -6.09106943e-03,  -3.21686491e-02,  -1.07312342e-03],\n",
       "          ..., \n",
       "          [ -1.47800148e-02,   7.77616128e-02,  -2.67065037e-02, ...,\n",
       "            -8.10234528e-03,  -1.15585206e-02,  -5.30505227e-03],\n",
       "          [ -1.39283072e-02,   1.69547591e-02,  -1.20282415e-02, ...,\n",
       "             1.25513040e-02,  -8.44068080e-02,  -4.48253192e-02],\n",
       "          [  2.55671684e-02,   7.02229328e-03,  -2.82986648e-02, ...,\n",
       "             1.17048556e-02,  -7.34802186e-02,  -2.06979234e-02]],\n",
       " \n",
       "         [[ -2.59410664e-02,  -4.97468375e-02,  -2.42083799e-02, ...,\n",
       "            -2.39597876e-02,   2.09030695e-02,   1.69499479e-02],\n",
       "          [ -4.78290301e-03,   1.04173329e-02,   8.31823424e-02, ...,\n",
       "            -3.18786576e-02,   3.48328054e-03,  -3.56311840e-03],\n",
       "          [ -3.81173752e-02,  -1.85197107e-02,  -1.43900532e-02, ...,\n",
       "            -1.41960718e-02,   3.14613059e-02,   4.11967095e-03],\n",
       "          ..., \n",
       "          [ -1.79932006e-02,   7.17700496e-02,  -1.99375115e-02, ...,\n",
       "            -6.12784317e-03,   1.66521706e-02,  -7.48346280e-03],\n",
       "          [ -8.91536921e-02,  -4.69055325e-02,  -1.37380632e-02, ...,\n",
       "            -8.06835108e-03,   6.04359731e-02,  -4.47445139e-02],\n",
       "          [ -1.00021079e-01,  -3.55393849e-02,  -2.46136412e-02, ...,\n",
       "            -7.50665693e-03,   9.11064222e-02,  -1.06519591e-02]],\n",
       " \n",
       "         [[ -9.84916389e-02,  -5.77464141e-02,  -4.49889433e-03, ...,\n",
       "            -2.21592579e-02,  -9.32130869e-03,   5.57853021e-02],\n",
       "          [  4.70533501e-03,   1.18583711e-02,   6.85855076e-02, ...,\n",
       "            -2.62385849e-02,  -2.82203127e-03,  -4.67023626e-03],\n",
       "          [ -2.28894763e-02,  -7.75412470e-03,  -9.86886956e-03, ...,\n",
       "            -1.22523597e-02,   4.30414118e-02,   1.28994938e-02],\n",
       "          ..., \n",
       "          [  2.93275771e-05,   1.62800644e-02,  -2.53228396e-02, ...,\n",
       "            -8.11440870e-03,   9.42004658e-03,  -1.69352964e-02],\n",
       "          [ -4.56118677e-03,  -3.88334878e-02,  -8.15101550e-04, ...,\n",
       "            -7.37672672e-05,   2.05828294e-01,  -1.84731018e-02],\n",
       "          [ -3.79626676e-02,  -1.82646457e-02,  -7.20302528e-03, ...,\n",
       "            -1.28044421e-03,   1.40015617e-01,   1.13147246e-02]]],\n",
       " \n",
       " \n",
       "        [[[ -1.11585744e-02,  -4.15539136e-03,  -6.83113467e-03, ...,\n",
       "             3.17358202e-03,  -6.52846992e-02,   8.59456360e-02],\n",
       "          [ -6.14583818e-03,   4.85422462e-03,   5.14627509e-02, ...,\n",
       "            -2.23777443e-02,  -1.03412592e-03,  -8.19014851e-03],\n",
       "          [ -1.00106997e-02,  -1.59974187e-03,  -1.14092128e-02, ...,\n",
       "            -3.87838250e-03,  -3.99293639e-02,   1.13589503e-02],\n",
       "          ..., \n",
       "          [ -1.68860350e-02,   5.18255346e-02,  -2.66014934e-02, ...,\n",
       "            -1.99763244e-03,   4.35560057e-03,  -4.49330434e-02],\n",
       "          [ -1.34146223e-02,   6.32185815e-03,  -7.33473897e-03, ...,\n",
       "             4.59014578e-03,  -2.98611149e-02,   3.69221941e-02],\n",
       "          [ -2.88858525e-02,  -4.22423892e-03,  -1.42897591e-02, ...,\n",
       "             1.11823296e-02,  -7.52132908e-02,   1.67242344e-02]],\n",
       " \n",
       "         [[ -1.02114283e-01,  -5.26558608e-02,  -1.00238100e-02, ...,\n",
       "            -1.37801170e-02,  -4.94753271e-02,   1.25953421e-01],\n",
       "          [  2.65349774e-03,   1.04075735e-02,   6.73149154e-02, ...,\n",
       "            -2.37589777e-02,   6.13968645e-04,  -9.96601582e-03],\n",
       "          [ -1.50703192e-02,  -1.28871305e-02,  -8.77845287e-03, ...,\n",
       "            -1.01640215e-02,  -4.76290248e-02,   1.36717530e-02],\n",
       "          ..., \n",
       "          [ -5.43789240e-03,   3.35888155e-02,  -2.11151708e-02, ...,\n",
       "            -3.83130647e-03,  -1.02301398e-02,  -5.32924160e-02],\n",
       "          [ -2.21891310e-02,  -4.92077954e-02,  -1.38867581e-02, ...,\n",
       "            -1.28568839e-02,  -9.37007815e-02,   5.59309907e-02],\n",
       "          [ -2.61166841e-02,  -3.50148268e-02,  -1.47816772e-02, ...,\n",
       "            -2.86548026e-03,  -1.01101905e-01,   1.94419883e-02]],\n",
       " \n",
       "         [[  2.73401570e-02,  -3.54428887e-02,   1.18577422e-03, ...,\n",
       "             5.02943760e-04,   4.51298095e-02,   1.23520821e-01],\n",
       "          [  9.48381796e-03,   1.12858564e-02,   5.32916747e-02, ...,\n",
       "            -1.81195941e-02,  -1.31687860e-03,  -1.01092532e-02],\n",
       "          [  3.73495184e-02,  -7.93821830e-03,  -5.94039401e-03, ...,\n",
       "            -7.96878152e-03,   1.53274648e-02,   9.63651482e-03],\n",
       "          ..., \n",
       "          [ -2.60413792e-02,  -2.53635142e-02,  -2.81382054e-02, ...,\n",
       "            -6.63971901e-03,  -7.26283342e-03,  -5.57855107e-02],\n",
       "          [  2.67488584e-02,  -4.73727398e-02,  -3.06198676e-03, ...,\n",
       "            -4.82000969e-03,   4.08617556e-02,   6.99444860e-02],\n",
       "          [  7.98859298e-02,  -2.87372041e-02,   6.38093508e-04, ...,\n",
       "             9.73386108e-04,   4.21557203e-02,   1.60824433e-02]]]], dtype=float32),\n",
       " array([-0.30912212,  0.36397225,  0.13737613,  0.07717966,  0.90521842,\n",
       "         0.08885256,  0.10789118, -0.23106739, -0.63180971,  0.18161367,\n",
       "        -0.33391494,  0.1961724 ,  0.43838617,  0.1938708 ,  0.10894354,\n",
       "         0.10315038, -1.02715135,  0.05252688,  0.13118458,  0.22851577,\n",
       "        -0.71377224,  0.21541549, -0.69819617,  0.04061132,  0.13955347,\n",
       "         0.28767544,  0.35358745,  0.39372951,  0.43452853, -0.48259264,\n",
       "         0.02631121,  0.09220165,  0.05196398,  0.55070502,  0.32368094,\n",
       "         0.07263482, -0.17745508,  0.37619719,  0.39344102,  0.17673127,\n",
       "        -0.15784228,  0.26051855,  0.08342359,  0.08603705, -0.09131282,\n",
       "         0.22932515,  0.29983151,  0.13511261, -0.38358289,  0.10912544,\n",
       "        -0.53432876,  0.4741787 , -0.0740848 ,  0.30046257,  0.12590808,\n",
       "         0.16480374,  0.24039429,  0.23401979, -0.19334187,  0.01663565,\n",
       "         0.27144948,  0.03385786,  0.06076292, -0.5825159 ], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[  1.66219637e-01,   1.42701536e-01,  -4.02133074e-03, ...,\n",
       "             6.18830323e-02,  -1.74050219e-02,  -3.00646629e-02],\n",
       "          [  9.46845207e-03,   3.87373753e-03,   5.08370474e-02, ...,\n",
       "            -2.77981255e-02,   1.71578722e-03,   6.82684872e-03],\n",
       "          [  6.32681325e-02,   2.12877449e-02,  -1.63462851e-02, ...,\n",
       "             8.80071952e-04,   6.68212073e-03,  -1.41169527e-03],\n",
       "          ..., \n",
       "          [  3.47735453e-03,   8.47014561e-02,  -4.07227464e-02, ...,\n",
       "            -1.13517242e-02,  -7.49272574e-03,   3.19109811e-03],\n",
       "          [  5.97230680e-02,   4.97662686e-02,  -3.23145301e-03, ...,\n",
       "             1.43113760e-02,   3.03176586e-02,  -4.23925333e-02],\n",
       "          [  1.33459508e-01,   4.95483428e-02,  -1.78809240e-02, ...,\n",
       "             2.25383770e-02,   3.02023385e-02,  -2.17075516e-02]],\n",
       " \n",
       "         [[  2.12008223e-01,   2.10124291e-02,  -1.47627257e-02, ...,\n",
       "             2.29585003e-02,   1.23113580e-02,  -3.08425371e-02],\n",
       "          [ -2.62276735e-03,   7.41990982e-03,   6.74035698e-02, ...,\n",
       "            -3.06593813e-02,   1.80781994e-03,   4.27331217e-03],\n",
       "          [  2.27198359e-02,  -1.07841268e-02,  -1.31092677e-02, ...,\n",
       "            -1.15751289e-02,   4.18374948e-02,  -1.92299916e-03],\n",
       "          ..., \n",
       "          [ -2.70068343e-03,   7.41156191e-02,  -3.32266316e-02, ...,\n",
       "            -1.10271834e-02,   1.39803635e-02,   5.34455152e-03],\n",
       "          [ -3.20507362e-02,  -2.40584593e-02,  -4.52420814e-03, ...,\n",
       "            -6.04031514e-03,   2.01963022e-01,  -5.04491478e-02],\n",
       "          [  1.68113951e-02,  -2.33167298e-02,  -1.40886903e-02, ...,\n",
       "            -7.79276015e-03,   1.28429353e-01,  -2.58185435e-02]],\n",
       " \n",
       "         [[ -5.91676170e-03,  -2.26227660e-02,   4.88118082e-03, ...,\n",
       "             4.14120237e-04,  -4.84162904e-02,   1.63637509e-03],\n",
       "          [ -3.93870287e-03,   9.07294825e-03,   5.36522120e-02, ...,\n",
       "            -2.56106481e-02,  -4.17683553e-03,   2.47438066e-03],\n",
       "          [ -3.07008065e-02,  -1.09782210e-02,  -3.69067676e-03, ...,\n",
       "            -1.19221844e-02,  -1.39761567e-02,   8.52897484e-03],\n",
       "          ..., \n",
       "          [  5.83549729e-03,   2.96191629e-02,  -3.56574245e-02, ...,\n",
       "            -1.01148067e-02,   5.05814888e-03,  -2.86818785e-03],\n",
       "          [ -7.80933872e-02,  -1.95693225e-02,   2.14811917e-02, ...,\n",
       "             7.42449379e-03,   5.41619956e-02,  -2.35791095e-02],\n",
       "          [ -7.82640576e-02,  -2.47034896e-02,   1.36249457e-02, ...,\n",
       "            -7.53268600e-03,  -2.59853844e-02,   4.52128658e-03]]],\n",
       " \n",
       " \n",
       "        [[[  1.99202314e-01,   5.03253266e-02,  -1.93236209e-02, ...,\n",
       "             1.62309762e-02,  -1.15361763e-02,   1.55755645e-03],\n",
       "          [ -1.38758810e-03,   4.52191290e-03,   6.65071160e-02, ...,\n",
       "            -3.00004296e-02,   1.73949811e-04,  -1.11935940e-03],\n",
       "          [  2.14256607e-02,   1.79773883e-03,  -1.76790040e-02, ...,\n",
       "            -6.09107222e-03,  -3.21675092e-02,  -1.07342622e-03],\n",
       "          ..., \n",
       "          [ -1.47773735e-02,   7.77611434e-02,  -2.67068036e-02, ...,\n",
       "            -8.10179114e-03,  -1.15612317e-02,  -5.30470535e-03],\n",
       "          [ -1.39286183e-02,   1.69543978e-02,  -1.20285181e-02, ...,\n",
       "             1.25513133e-02,  -8.44064876e-02,  -4.48252708e-02],\n",
       "          [  2.55669076e-02,   7.02200923e-03,  -2.82988381e-02, ...,\n",
       "             1.17047904e-02,  -7.34798759e-02,  -2.06979569e-02]],\n",
       " \n",
       "         [[ -2.59411763e-02,  -4.97471653e-02,  -2.42083166e-02, ...,\n",
       "            -2.39595380e-02,   2.09042896e-02,   1.69495493e-02],\n",
       "          [ -4.78394469e-03,   1.04162749e-02,   8.31828043e-02, ...,\n",
       "            -3.18785906e-02,   3.48532223e-03,  -3.56349163e-03],\n",
       "          [ -3.81173268e-02,  -1.85197778e-02,  -1.43897599e-02, ...,\n",
       "            -1.41960401e-02,   3.14627923e-02,   4.11934126e-03],\n",
       "          ..., \n",
       "          [ -1.79906171e-02,   7.17695355e-02,  -1.99377909e-02, ...,\n",
       "            -6.12733979e-03,   1.66494548e-02,  -7.48307304e-03],\n",
       "          [ -8.91537815e-02,  -4.69057038e-02,  -1.37382066e-02, ...,\n",
       "            -8.06817506e-03,   6.04364201e-02,  -4.47445251e-02],\n",
       "          [ -1.00021072e-01,  -3.55394967e-02,  -2.46136747e-02, ...,\n",
       "            -7.50659592e-03,   9.11071002e-02,  -1.06520802e-02]],\n",
       " \n",
       "         [[ -9.84916314e-02,  -5.77467456e-02,  -4.49885195e-03, ...,\n",
       "            -2.21592002e-02,  -9.31982882e-03,   5.57847545e-02],\n",
       "          [  4.70428262e-03,   1.18573187e-02,   6.85859770e-02, ...,\n",
       "            -2.62385085e-02,  -2.81999749e-03,  -4.67060320e-03],\n",
       "          [ -2.28894763e-02,  -7.75419502e-03,  -9.86857712e-03, ...,\n",
       "            -1.22523904e-02,   4.30430584e-02,   1.28991511e-02],\n",
       "          ..., \n",
       "          [  3.17408885e-05,   1.62794497e-02,  -2.53230333e-02, ...,\n",
       "            -8.11391138e-03,   9.41734388e-03,  -1.69348791e-02],\n",
       "          [ -4.56115743e-03,  -3.88337374e-02,  -8.15300620e-04, ...,\n",
       "            -7.37103619e-05,   2.05828756e-01,  -1.84731055e-02],\n",
       "          [ -3.79626416e-02,  -1.82648618e-02,  -7.20315380e-03, ...,\n",
       "            -1.28052803e-03,   1.40016347e-01,   1.13146091e-02]]],\n",
       " \n",
       " \n",
       "        [[[ -1.11588463e-02,  -4.15572431e-03,  -6.83110580e-03, ...,\n",
       "             3.17353872e-03,  -6.52836338e-02,   8.59453008e-02],\n",
       "          [ -6.14687428e-03,   4.85314382e-03,   5.14631867e-02, ...,\n",
       "            -2.23776661e-02,  -1.03211578e-03,  -8.19051359e-03],\n",
       "          [ -1.00108711e-02,  -1.59980578e-03,  -1.14089968e-02, ...,\n",
       "            -3.87842115e-03,  -3.99281308e-02,   1.13586169e-02],\n",
       "          ..., \n",
       "          [ -1.68833174e-02,   5.18251359e-02,  -2.66016088e-02, ...,\n",
       "            -1.99715630e-03,   4.35297936e-03,  -4.49326448e-02],\n",
       "          [ -1.34150572e-02,   6.32157968e-03,  -7.33512500e-03, ...,\n",
       "             4.59011411e-03,  -2.98608597e-02,   3.69221680e-02],\n",
       "          [ -2.88861878e-02,  -4.22447408e-03,  -1.42899491e-02, ...,\n",
       "             1.11822439e-02,  -7.52129033e-02,   1.67241171e-02]],\n",
       " \n",
       "         [[ -1.02114417e-01,  -5.26560731e-02,  -1.00236870e-02, ...,\n",
       "            -1.37800332e-02,  -4.94740531e-02,   1.25952929e-01],\n",
       "          [  2.65245233e-03,   1.04065072e-02,   6.73153773e-02, ...,\n",
       "            -2.37588882e-02,   6.15965633e-04,  -9.96637437e-03],\n",
       "          [ -1.50703238e-02,  -1.28871705e-02,  -8.77815206e-03, ...,\n",
       "            -1.01640485e-02,  -4.76275869e-02,   1.36714280e-02],\n",
       "          ..., \n",
       "          [ -5.43522323e-03,   3.35883461e-02,  -2.11152695e-02, ...,\n",
       "            -3.83087015e-03,  -1.02327932e-02,  -5.32920137e-02],\n",
       "          [ -2.21893080e-02,  -4.92078848e-02,  -1.38870105e-02, ...,\n",
       "            -1.28567815e-02,  -9.37004313e-02,   5.59309833e-02],\n",
       "          [ -2.61167344e-02,  -3.50149199e-02,  -1.47817172e-02, ...,\n",
       "            -2.86548585e-03,  -1.01101264e-01,   1.94418617e-02]],\n",
       " \n",
       "         [[  2.73400601e-02,  -3.54430377e-02,   1.18594442e-03, ...,\n",
       "             5.02898183e-04,   4.51314524e-02,   1.23520352e-01],\n",
       "          [  9.48276650e-03,   1.12847956e-02,   5.32921217e-02, ...,\n",
       "            -1.81194916e-02,  -1.31488300e-03,  -1.01096043e-02],\n",
       "          [  3.73494849e-02,  -7.93821830e-03,  -5.94006805e-03, ...,\n",
       "            -7.96884671e-03,   1.53291300e-02,   9.63621493e-03],\n",
       "          ..., \n",
       "          [ -2.60388609e-02,  -2.53640916e-02,  -2.81382296e-02, ...,\n",
       "            -6.63930690e-03,  -7.26550212e-03,  -5.57850935e-02],\n",
       "          [  2.67488305e-02,  -4.73727770e-02,  -3.06218420e-03, ...,\n",
       "            -4.82000085e-03,   4.08622809e-02,   6.99445158e-02],\n",
       "          [  7.98859224e-02,  -2.87372880e-02,   6.38040772e-04, ...,\n",
       "             9.73258808e-04,   4.21566777e-02,   1.60823725e-02]]]], dtype=float32),\n",
       " array([-0.30912212,  0.36397225,  0.13737613,  0.07717966,  0.90521842,\n",
       "         0.08885256,  0.10789118, -0.23106739, -0.63180971,  0.18161367,\n",
       "        -0.33391494,  0.1961724 ,  0.43838617,  0.1938708 ,  0.10894354,\n",
       "         0.10315038, -1.02715135,  0.05252687,  0.13118458,  0.2285158 ,\n",
       "        -0.71377224,  0.21541549, -0.69819617,  0.04061132,  0.13955347,\n",
       "         0.28767544,  0.35358745,  0.39372951,  0.43452853, -0.48259264,\n",
       "         0.02631123,  0.09220165,  0.05196397,  0.55070502,  0.32368094,\n",
       "         0.07263484, -0.17745508,  0.37619719,  0.39344102,  0.17673127,\n",
       "        -0.15784228,  0.26051855,  0.08342359,  0.08603704, -0.09131281,\n",
       "         0.22932515,  0.29983151,  0.13511261, -0.38358289,  0.10912544,\n",
       "        -0.53432876,  0.4741787 , -0.0740848 ,  0.30046257,  0.12590808,\n",
       "         0.16480374,  0.24039429,  0.23401979, -0.19334187,  0.01663565,\n",
       "         0.27144948,  0.03385786,  0.06076293, -0.5825159 ], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00413576, -0.0006756 , -0.0037106 , ..., -0.00403977,\n",
       "         -0.00420736,  0.00389873],\n",
       "        [-0.00413694, -0.00323165,  0.00388925, ...,  0.00040348,\n",
       "         -0.00098363, -0.00389307],\n",
       "        [ 0.00017147, -0.0022986 , -0.00253703, ..., -0.00378009,\n",
       "         -0.00244464,  0.00041722],\n",
       "        ..., \n",
       "        [ 0.00413261, -0.00360248,  0.00223137, ..., -0.00176643,\n",
       "         -0.00192812,  0.00222079],\n",
       "        [-0.00187596,  0.00193346,  0.00126447, ...,  0.00450095,\n",
       "         -0.00288231,  0.0002259 ],\n",
       "        [-0.00257495,  0.00263139,  0.00189016, ...,  0.00191831,\n",
       "          0.00459433,  0.00021668]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0040932 , -0.00067632, -0.00371132, ..., -0.00404049,\n",
       "         -0.00420808,  0.003898  ],\n",
       "        [-0.00413374, -0.00323171,  0.00388919, ...,  0.00040342,\n",
       "         -0.00098368, -0.00389312],\n",
       "        [ 0.00018196, -0.00229867, -0.0025371 , ..., -0.00378016,\n",
       "         -0.00244471,  0.00041715],\n",
       "        ..., \n",
       "        [ 0.00413293, -0.00360249,  0.00223136, ..., -0.00176644,\n",
       "         -0.00192813,  0.00222078],\n",
       "        [-0.00187535,  0.00193345,  0.00126445, ...,  0.00450093,\n",
       "         -0.00288233,  0.00022588],\n",
       "        [-0.00257116,  0.00263122,  0.00188998, ...,  0.00191814,\n",
       "          0.00459415,  0.00021651]], dtype=float32),\n",
       " array([ 0.0072673 , -0.00011194, -0.00011224, -0.0001119 ,  0.0008502 ,\n",
       "         0.00016745,  0.00064668,  0.000168  , -0.00011243, -0.00011149,\n",
       "         0.00041688,  0.00041787, -0.00011199, -0.00011156, -0.00011221,\n",
       "        -0.00011188, -0.00011194, -0.00011165, -0.00011198, -0.00011171,\n",
       "         0.00103112,  0.00217623, -0.00011184, -0.00011191, -0.00011199,\n",
       "        -0.00011188, -0.00011223,  0.0010325 , -0.00011227, -0.00011202,\n",
       "        -0.00011177, -0.00011187, -0.00011168, -0.00011219, -0.00011203,\n",
       "        -0.00011193, -0.00011195, -0.00011189, -0.00011223, -0.00011208,\n",
       "        -0.00011226, -0.00011144, -0.00011193, -0.00011225, -0.00011211,\n",
       "         0.00084917, -0.00011193, -0.00011175, -0.00011181, -0.00011201,\n",
       "        -0.00011211, -0.0001117 , -0.00011233, -0.00011196, -0.0001121 ,\n",
       "        -0.00011176, -0.00011182,  0.00041776,  0.00161546,  0.00064527,\n",
       "        -0.00011212, -0.00011205, -0.00011166,  0.00064551, -0.00011172,\n",
       "         0.00064352, -0.00011169, -0.00011215, -0.00011249, -0.00011175,\n",
       "        -0.00011188, -0.00011172, -0.00011182, -0.00011186, -0.00011187,\n",
       "        -0.00011179, -0.00011196, -0.00011213, -0.00011171, -0.00011203,\n",
       "        -0.00011174, -0.00011163, -0.00011215, -0.000112  , -0.0001119 ,\n",
       "        -0.00011221, -0.00011153, -0.00011213, -0.00011209, -0.00011201,\n",
       "        -0.00011162,  0.00016676, -0.00011178, -0.00011157,  0.00016818,\n",
       "        -0.00011196, -0.00011214, -0.00011183, -0.00011182, -0.00011204,\n",
       "        -0.00011163, -0.00011191, -0.00011214, -0.0001116 , -0.00011188,\n",
       "        -0.00011192, -0.0001122 , -0.00011186, -0.00011214, -0.00011197,\n",
       "        -0.00011177, -0.00011208, -0.00011187, -0.0001121 , -0.00011216,\n",
       "         0.0008505 , -0.00011199, -0.00011164, -0.00011186, -0.00011187,\n",
       "        -0.00011195, -0.00011171, -0.00011186, -0.00011165, -0.00011219,\n",
       "        -0.0001119 , -0.00011215, -0.00011213, -0.00011182, -0.00011165,\n",
       "        -0.00011188, -0.00011185, -0.00011181, -0.0001121 , -0.00011163,\n",
       "        -0.00011249, -0.00011194, -0.00011211, -0.00011183, -0.00011196,\n",
       "        -0.00011174, -0.00011191, -0.00011203, -0.00011213,  0.00016774,\n",
       "        -0.00011217, -0.00011225, -0.00011165, -0.00011227, -0.0001118 ,\n",
       "        -0.00011219, -0.00011204, -0.00011167, -0.00011186, -0.0001121 ,\n",
       "        -0.00011177, -0.00011248, -0.00011221, -0.00011184, -0.0001116 ,\n",
       "        -0.00011182,  0.00041677, -0.00011176,  0.00085044, -0.00011221,\n",
       "        -0.00011247, -0.00011191, -0.00011224, -0.00011212, -0.000112  ,\n",
       "        -0.00011164, -0.00011228, -0.00011184, -0.00011202, -0.0001124 ,\n",
       "        -0.00011192, -0.0001119 , -0.00011226, -0.00011161, -0.00011203,\n",
       "        -0.00011187, -0.00011199, -0.0001123 , -0.00011193, -0.00011236,\n",
       "        -0.00011192, -0.0001122 , -0.00011179, -0.00011177, -0.00011191,\n",
       "         0.00041802, -0.00011161, -0.00011212, -0.00011196, -0.00011199,\n",
       "        -0.00011193, -0.00011198, -0.00011214, -0.00011199, -0.00011171,\n",
       "        -0.00011245, -0.00011223, -0.00011206,  0.00103283, -0.00011175,\n",
       "        -0.00011186, -0.00011155, -0.00011147, -0.00011192, -0.00011166,\n",
       "        -0.00011218, -0.00011199, -0.00011192, -0.00011211, -0.00011216,\n",
       "        -0.00011188, -0.00011164, -0.00011168, -0.00011194, -0.00011173,\n",
       "        -0.00011185, -0.00011201, -0.00011201, -0.00011201, -0.00011199,\n",
       "        -0.00011199, -0.00011209, -0.00011224, -0.00011219, -0.0001123 ], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /data/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST = input_data.read_data_sets(\"/data/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST.train.images.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
